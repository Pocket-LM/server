import asyncio
import json
from datasets import Dataset
from httpx import AsyncClient
from datetime import datetime, timezone
from langchain.messages import HumanMessage
from ragas import evaluate
from ragas.metrics import (
    context_precision,
    context_recall,
    answer_relevancy,
    faithfulness,
)

from src.configs.settings import settings
from src.schemas.langgraph import AgentState
from src.utils.logging import get_logger
from src.utils.langgraph.agent import get_checkpoint_saver, get_langgraph_agent

"""
  The used dataset contains the following fields:

    user_input: The question to be answered
    reference: Ground truth answer for evaluation (much better than response)
    response: Generated answer from the system
    retrieved_contexts: List of relevant context passages retrieved for answering the question

  Context Pression:
    Evaluates whether retrieved contexts (generated by RAG retrieval) are useful for answering a question by comparing each context against a reference answer (ground truth answer for evaluation).
  
  Context Utilization:
    Evaluates whether retrieved contexts are useful by comparing each context against the generated response. Use this when you don't have a reference answer but have the response that was generated.
"""

logger = get_logger(__name__)


async def embed_retrieved_contexts():
    with open("test/data/hf_dataset.json", "r") as f:
        hf_dataset = json.load(f)

    async with AsyncClient(base_url="http://localhost:8000/api/v1") as client:
        for idx, dt in enumerate(hf_dataset):
            try:
                await client.post(
                    url="/capture",
                    data={
                        "type": "selection",
                        "knowledgeBase": "default",
                        "selection": dt["retrieved_contexts"][0],
                        "url": "http://example.com/document",
                    },
                )
            except Exception as e:
                logger.info(f"Error embedding context for index {idx}: {e}")
                return False

    logger.info("Successfully embedded all retrieved contexts.")
    return True


async def prepare_test_dataset():
    with open("test/data/hf_dataset.json", "r") as f:
        hf_dataset = json.load(f)

    generated_dataset: list[dict] = []
    for dt in hf_dataset:
        async with get_langgraph_agent(
            user_id=settings.DEFAULT_USER_ID, thread_id=settings.DEFAULT_SESSION_ID
        ) as (
            graph,
            config,
        ):
            # To only keep a single turn interaction
            async with get_checkpoint_saver() as checkpoint_saver:
                if await checkpoint_saver.aget(config=config):
                    await checkpoint_saver.adelete_thread(
                        thread_id=settings.DEFAULT_SESSION_ID
                    )

            human_msg = HumanMessage(
                content=dt["user_input"],
                additional_kwargs={
                    "generated_at": datetime.now(timezone.utc).isoformat()
                },
            )

            try:
                state = await graph.ainvoke(
                    AgentState(
                        messages=[human_msg],
                        summary="",
                        history=[human_msg],
                    ),
                    config,
                    stream_mode="values",
                )

                retrieved_contexts: list[str] = []
                for msg in reversed(state.get("messages", [])):
                    if msg.type == "tool":
                        retrieved_contexts.extend(msg.content.split("\n\n\n\n"))

                generated_dataset.append(
                    {
                        "user_input": dt["user_input"],
                        "reference": dt["reference"],
                        "response": state.get("messages", [])[-1].content,
                        "retrieved_contexts": retrieved_contexts,
                    }
                )

                # To avoid rate limiting issues
                await asyncio.sleep(60)

            except Exception as e:
                logger.info(
                    f"Error processing message for input: {dt['user_input']}: {e}"
                )
                return False

    with open("test/data/generated_dataset.json", "w") as f:
        json.dump(generated_dataset, f, indent=2)

    return True


async def main():
    # await embed_retrieved_contexts()

    # if not (await prepare_test_dataset()):
    #     logger.info("Failed to prepare test dataset.")
    #     return

    # result = evaluate(
    #     dataset=Dataset.from_dict(generated),
    #     metrics=[
    #         context_precision,
    #         context_recall,
    #         answer_relevancy,
    #         faithfulness,
    #     ],
    # )

    # df = result.to_pandas()
    # logger.info("Evaluation Results:")
    # logger.info(df)

    pass


if __name__ == "__main__":
    asyncio.run(main())
